# Omnilingual ASR ç¹é«”ä¸­æ–‡ä½¿ç”¨æŒ‡å—

> åŸºæ–¼ Meta çš„ Omnilingual ASRï¼Œæ·»åŠ ä¸²æµè½‰è­¯èˆ‡è‡ªå‹•éŸ³è¨Šåˆ‡å‰²åŠŸèƒ½

## ğŸ¯ é‡è¦æ›´æ–°

æœ¬å¢å¼·ç‰ˆæœ¬æ–°å¢å…©å¤§æ ¸å¿ƒåŠŸèƒ½ï¼š

### 1. ğŸ™ï¸ å³æ™‚ä¸²æµè½‰è­¯
- æ”¯æ´éº¥å…‹é¢¨å³æ™‚èªéŸ³è¾¨è­˜
- ä½å»¶é²ï¼ˆ< 2 ç§’ï¼‰
- æ”¯æ´ CTC èˆ‡ LLM æ¨¡å‹
- Web ä»‹é¢æ“ä½œç°¡å–®

### 2. âœ‚ï¸ è‡ªå‹•éŸ³è¨Šåˆ‡å‰²
- **ä¸å†é™åˆ¶ 40 ç§’**ï¼
- è‡ªå‹•è™•ç†ä»»æ„é•·åº¦éŸ³è¨Š
- æ”¯æ´å¯é…ç½®æ™‚é–“æˆ³è¨˜
- æ™ºèƒ½é‡ç–Šé¿å…å¥å­è¢«åˆ‡æ–·

---

## ğŸ“¦ å®‰è£

### ç³»çµ±éœ€æ±‚

- Python 3.8+
- CUDA 11.8+ ï¼ˆGPU åŠ é€Ÿï¼Œå¯é¸ï¼‰
- 16GB RAMï¼ˆå»ºè­°ï¼‰

### å®‰è£æ­¥é©Ÿ

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/JonesHong/omnilingual-asr.git
cd omnilingual-asr

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 3. å®‰è£ä¾è³´
pip install -e .

# 4. å®‰è£ Web Demo ä¾è³´ï¼ˆå¯é¸ï¼‰
pip install -r requirements_web.txt
```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åŠŸèƒ½ 1ï¼šå³æ™‚ä¸²æµè½‰è­¯

#### å•Ÿå‹• Web Demo

```bash
# å•Ÿå‹•ä¼ºæœå™¨
python demos/web_streaming_server.py
```

ç„¶å¾Œåœ¨ç€è¦½å™¨é–‹å•Ÿï¼š`http://localhost:8000`

#### é…ç½®é¸é …

ç·¨è¼¯ `demos/web_streaming_server.py` èª¿æ•´åƒæ•¸ï¼š

```python
# æ¨¡å‹é¸æ“‡
MODEL_CARD = "omniASR_LLM_3B"  # æˆ– CTC_300M, LLM_1B ç­‰

# èªè¨€è¨­å®š
LANG = "cmn_Hant"  # ç¹é«”ä¸­æ–‡

# VAD åƒæ•¸ï¼ˆæ§åˆ¶å»¶é²ï¼‰
MAX_SEGMENT_DURATION_MS = 2000  # æœ€å¤§ç‰‡æ®µé•·åº¦
MIN_SILENCE_DURATION_MS = 500   # éœéŸ³ç­‰å¾…æ™‚é–“
MIN_SPEECH_DURATION_MS = 250    # æœ€å°èªéŸ³é•·åº¦
```

#### æ”¯æ´çš„æ¨¡å‹

| æ¨¡å‹ | ç”¨é€” | å»¶é² | æº–ç¢ºåº¦ |
|------|------|------|--------|
| `omniASR_CTC_300M` | å¿«é€Ÿè¾¨è­˜ | æ¥µä½ | ä¸­ |
| `omniASR_CTC_1B` | å¹³è¡¡ | ä½ | ä¸­é«˜ |
| `omniASR_LLM_300M` | é«˜æº–ç¢ºåº¦ | ä¸­ | é«˜ |
| `omniASR_LLM_3B` | æœ€é«˜æº–ç¢ºåº¦ | ä¸­é«˜ | æ¥µé«˜ |

#### èªè¨€ä»£ç¢¼

å¸¸ç”¨èªè¨€ä»£ç¢¼ï¼š

- `cmn_Hant` - ç¹é«”ä¸­æ–‡
- `cmn_Hans` - ç°¡é«”ä¸­æ–‡
- `eng_Latn` - è‹±æ–‡
- `jpn_Jpan` - æ—¥æ–‡
- `kor_Hang` - éŸ“æ–‡

å®Œæ•´åˆ—è¡¨ï¼š[lang_ids.py](../src/omnilingual_asr/models/wav2vec2_llama/lang_ids.py)

---

### åŠŸèƒ½ 2ï¼šè‡ªå‹•éŸ³è¨Šåˆ‡å‰²

#### åŸºæœ¬ä½¿ç”¨

```python
from omnilingual_asr.enhanced_pipeline import (
    EnhancedASRPipeline,
    TimestampFormat,
    TimeFormat
)
import torchaudio

# 1. è¼‰å…¥éŸ³è¨Šï¼ˆä»»æ„é•·åº¦ï¼‰
waveform, sr = torchaudio.load("long_audio.mp3")

# 2. åˆå§‹åŒ– Pipeline
pipeline = EnhancedASRPipeline(
    model_card="omniASR_LLM_3B",
    device="cuda"  # æˆ– "cpu"
)

# 3. è½‰è­¯ï¼ˆè‡ªå‹•åˆ‡å‰²ï¼‰
result = pipeline.transcribe(
    inp=[{
        "waveform": waveform.squeeze(0),
        "sample_rate": sr
    }],
    lang=["cmn_Hant"],
    chunk_duration=30.0,  # æ¯æ®µ 30 ç§’ï¼ˆå¿…é ˆ <= 40ï¼‰
    overlap=1.0,  # é‡ç–Š 1 ç§’
    timestamp_format=TimestampFormat.DETAILED,
    time_format=TimeFormat.MMSS
)

print(result[0])
```

#### è¼¸å‡ºç¯„ä¾‹

**ç„¡æ™‚é–“æˆ³è¨˜**ï¼š
```
ä»€éº¼æ˜¯ä¸Šå¸çš„é“é‚£ä½ æ‡‰è©²çŸ¥é“å°±æ˜¯ä¸Šå¸çš„é“ä½ æ²’æœ‰èªªæˆ‘åœ¨èªªèˆ‡ä¸Šå¸åŒåœ¨...
```

**ç°¡æ˜“æ™‚é–“æˆ³è¨˜**ï¼š
```
[00:00] ä»€éº¼æ˜¯ä¸Šå¸çš„é“é‚£ä½ æ‡‰è©²çŸ¥é“å°±æ˜¯ä¸Šå¸çš„é“
[00:30] ä½ æ²’æœ‰èªªæˆ‘åœ¨èªªèˆ‡ä¸Šå¸åŒåœ¨å€’æ˜¯è–éˆå¾…åˆ°äººå®¶
[01:00] é€™å€‹äººæ°´è–éˆå€Ÿè‘—å¢“å®¤å°±æ¥­çš„å…ˆçŸ¥è·Ÿæ–°ç´„çš„å¸«å¾’
```

**è©³ç´°æ™‚é–“æˆ³è¨˜**ï¼š
```
[00:00 - 00:30] ä»€éº¼æ˜¯ä¸Šå¸çš„é“é‚£ä½ æ‡‰è©²çŸ¥é“å°±æ˜¯ä¸Šå¸çš„é“
[00:30 - 01:00] ä½ æ²’æœ‰èªªæˆ‘åœ¨èªªèˆ‡ä¸Šå¸åŒåœ¨å€’æ˜¯è–éˆå¾…åˆ°äººå®¶
[01:00 - 01:30] é€™å€‹äººæ°´è–éˆå€Ÿè‘—å¢“å®¤å°±æ¥­çš„å…ˆçŸ¥è·Ÿæ–°ç´„çš„å¸«å¾’
```

#### æ™‚é–“æˆ³è¨˜é¸é …

```python
# 1. ç„¡æ™‚é–“æˆ³è¨˜
timestamp_format=TimestampFormat.NONE

# 2. ç°¡æ˜“æ™‚é–“æˆ³è¨˜
timestamp_format=TimestampFormat.SIMPLE

# 3. è©³ç´°æ™‚é–“æˆ³è¨˜
timestamp_format=TimestampFormat.DETAILED

# æ™‚é–“æ ¼å¼
time_format=TimeFormat.SECONDS   # 5.2s
time_format=TimeFormat.MMSS      # 00:05
time_format=TimeFormat.HHMMSS    # 00:00:05
```

#### è‡ªè¨‚æ™‚é–“æˆ³è¨˜æ¨¡æ¿

```python
result = pipeline.transcribe(
    inp=inp,
    timestamp_format=TimestampFormat.SIMPLE,
    time_format=TimeFormat.SECONDS,
    timestamp_template="â±ï¸ {start} | {text}"
)
# è¼¸å‡º: â±ï¸ 5.2s | æ–‡å­—å…§å®¹
```

å¯ç”¨è®Šæ•¸ï¼š
- `{start}` - é–‹å§‹æ™‚é–“
- `{end}` - çµæŸæ™‚é–“
- `{text}` - æ–‡å­—å…§å®¹
- `{duration}` - æŒçºŒæ™‚é–“

---

## ğŸ“š è©³ç´°æ–‡æª”

### ä¸²æµè½‰è­¯

- [ä¸²æµè½‰è­¯å®Œæ•´æŒ‡å—](./docs/STREAMING_ASR_GUIDE.md)

### éŸ³è¨Šåˆ‡å‰²

- [EnhancedASRPipeline å®Œæ•´æŒ‡å—](./docs/ENHANCED_PIPELINE_GUIDE.md)
- [API åƒè€ƒ](../src/omnilingual_asr/enhanced_pipeline.py)

---

## ğŸ¨ é€²éšåŠŸèƒ½

### 1. æ‰¹æ¬¡è™•ç†å¤šå€‹æª”æ¡ˆ

```python
# æº–å‚™å¤šå€‹éŸ³è¨Š
files = ["audio1.mp3", "audio2.wav", "audio3.flac"]
inp = []

for file in files:
    waveform, sr = torchaudio.load(file)
    inp.append({
        "waveform": waveform.squeeze(0),
        "sample_rate": sr
    })

# æ‰¹æ¬¡è½‰è­¯
results = pipeline.transcribe(
    inp=inp,
    lang=["cmn_Hant"] * len(files),
    timestamp_format=TimestampFormat.SIMPLE
)

for i, result in enumerate(results):
    print(f"\næª”æ¡ˆ {i+1}: {files[i]}")
    print(result)
```

### 2. ç”Ÿæˆ SRT å­—å¹•

```python
result = pipeline.transcribe(
    inp=inp,
    timestamp_format=TimestampFormat.DETAILED,
    time_format=TimeFormat.HHMMSS,
    timestamp_template="{start} --> {end}\n{text}"
)

# åŠ å…¥åºè™Ÿ
lines = result[0].split('\n\n')
srt_content = []
for i, line in enumerate(lines, 1):
    srt_content.append(f"{i}\n{line}\n")

with open("output.srt", "w", encoding="utf-8") as f:
    f.write("\n".join(srt_content))
```

### 3. èª¿æ•´ Web Demo æ‰“å­—é€Ÿåº¦

ç·¨è¼¯ `./demos/web_streaming_server.py` ç¬¬ 140 è¡Œï¼š

```javascript
const TYPING_SPEED = 30; // æ¯«ç§’/å­—ç¬¦
```

é€Ÿåº¦å»ºè­°ï¼š
- `10-20ms` - æ¥µå¿«
- `30-50ms` - æ¨è–¦
- `60-80ms` - æ…¢é€Ÿ

---

## âš™ï¸ æ€§èƒ½å„ªåŒ–

### GPU è¨˜æ†¶é«”ä¸è¶³

```python
# ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
pipeline = EnhancedASRPipeline(
    model_card="omniASR_CTC_300M",  # åªéœ€ ~2GB
    device="cuda"
)

# æˆ–ä½¿ç”¨ CPU
pipeline = EnhancedASRPipeline(
    model_card="omniASR_LLM_1B",
    device="cpu"
)
```

### åŠ å¿«è™•ç†é€Ÿåº¦

```python
# ä½¿ç”¨è¼ƒå¤§çš„ chunk_duration
result = pipeline.transcribe(
    inp=inp,
    chunk_duration=35.0,  # æ¥è¿‘ä¸Šé™
    overlap=0.5  # è¼ƒå°çš„é‡ç–Š
)
```

### é™ä½å»¶é²ï¼ˆä¸²æµï¼‰

```python
# server.py é…ç½®
MAX_SEGMENT_DURATION_MS = 1500  # é™ä½åˆ° 1.5 ç§’
MIN_SILENCE_DURATION_MS = 300   # é™ä½åˆ° 300ms
```

---

## ğŸ› å¸¸è¦‹å•é¡Œ

### Q: ç‚ºä»€éº¼ä¸²æµæœƒæœ‰ç–Šå­—ï¼Ÿ
A: å·²ä¿®æ­£ï¼ä½¿ç”¨äº†æ–‡å­—å»é‡åŠŸèƒ½ï¼ˆ`text_utils.py`ï¼‰ã€‚å¦‚æœä»æœ‰å•é¡Œï¼Œè«‹æª¢æŸ¥ `lang` åƒæ•¸æ˜¯å¦æ­£ç¢ºï¼ˆä¾‹å¦‚ `cmn_Hant` è€Œé `cmn`ï¼‰ã€‚

### Q: éŸ³è¨Šåˆ‡å‰²å¾Œæ™‚é–“æˆ³è¨˜ä¸æº–ç¢ºï¼Ÿ
A: èª¿æ•´ `overlap` åƒæ•¸ã€‚å»ºè­° 0.5-2.0 ç§’ã€‚

### Q: Web Demo ç„¡æ³•ä½¿ç”¨éº¥å…‹é¢¨ï¼ˆWSLï¼‰ï¼Ÿ
A: WSL ç„¡æ³•ç›´æ¥è¨ªå• Windows éº¥å…‹é¢¨ã€‚è«‹åœ¨ Windows ç€è¦½å™¨ä¸­é–‹å•Ÿ `http://localhost:8000`ã€‚

### Q: chunk_duration å¯ä»¥è¶…é 40 ç§’å—ï¼Ÿ
A: ä¸è¡Œï¼Œé€™æ˜¯æ¨¡å‹çš„ç¡¬æ€§é™åˆ¶ã€‚è¶…éæœƒå ±éŒ¯ã€‚

### Q: æ”¯æ´å“ªäº›éŸ³è¨Šæ ¼å¼ï¼Ÿ
A: æ”¯æ´æ‰€æœ‰ `torchaudio` æ”¯æ´çš„æ ¼å¼ï¼šMP3, WAV, FLAC, OGG ç­‰ã€‚

---

## ğŸ“Š æ¨¡å‹é¸æ“‡å»ºè­°

### ä¸²æµè½‰è­¯

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | åŸå›  |
|------|---------|------|
| å³æ™‚å­—å¹• | `omniASR_CTC_300M` | æ¥µä½å»¶é² |
| æœƒè­°è¨˜éŒ„ | `omniASR_LLM_1B` | å¹³è¡¡æº–ç¢ºåº¦èˆ‡é€Ÿåº¦ |
| é«˜å“è³ªè½‰è­¯ | `omniASR_LLM_3B` | æœ€é«˜æº–ç¢ºåº¦ |

### æª”æ¡ˆè½‰è­¯

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | åŸå›  |
|------|---------|------|
| å¿«é€Ÿè‰ç¨¿ | `omniASR_CTC_1B` | å¿«é€Ÿ |
| æ­£å¼æ–‡æª” | `omniASR_LLM_3B` | é«˜æº–ç¢ºåº¦ |
| å¤šèªè¨€æ··åˆ | `omniASR_LLM_7B` | æœ€ä½³èªè¨€è­˜åˆ¥ |

---

## ğŸ¯ ä½¿ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1ï¼šæœƒè­°è¨˜éŒ„

```python
from omnilingual_asr.enhanced_pipeline import *
import torchaudio

# è¼‰å…¥æœƒè­°éŒ„éŸ³ï¼ˆå¯èƒ½å¾ˆé•·ï¼‰
waveform, sr = torchaudio.load("meeting.mp3")

pipeline = EnhancedASRPipeline(
    model_card="omniASR_LLM_3B",
    device="cuda"
)

result = pipeline.transcribe(
    inp=[{"waveform": waveform.squeeze(0), "sample_rate": sr}],
    lang=["cmn_Hant"],
    timestamp_format=TimestampFormat.DETAILED,
    time_format=TimeFormat.MMSS
)

# å„²å­˜çµæœ
with open("meeting_transcript.txt", "w", encoding="utf-8") as f:
    f.write(result[0])
```

### ç¯„ä¾‹ 2ï¼šå³æ™‚å­—å¹•

```bash
# å•Ÿå‹• Web Demo
python server.py

# åœ¨ server.py ä¸­é…ç½®
MODEL_CARD = "omniASR_CTC_1B"  # ä½å»¶é²
LANG = "cmn_Hant"
MAX_SEGMENT_DURATION_MS = 1500  # 1.5 ç§’
```

### ç¯„ä¾‹ 3ï¼šå½±ç‰‡å­—å¹•ç”Ÿæˆ

```python
# å¾å½±ç‰‡æå–éŸ³è¨Šï¼ˆéœ€è¦ ffmpegï¼‰
import subprocess
subprocess.run([
    "ffmpeg", "-i", "video.mp4",
    "-vn", "-acodec", "pcm_s16le",
    "-ar", "16000", "-ac", "1",
    "audio.wav"
])

# è½‰è­¯ä¸¦ç”Ÿæˆ SRT
waveform, sr = torchaudio.load("audio.wav")
result = pipeline.transcribe(
    inp=[{"waveform": waveform.squeeze(0), "sample_rate": sr}],
    lang=["cmn_Hant"],
    timestamp_format=TimestampFormat.DETAILED,
    time_format=TimeFormat.HHMMSS,
    timestamp_template="{start} --> {end}\n{text}"
)

# å„²å­˜ SRT
lines = result[0].split('\n\n')
with open("subtitles.srt", "w", encoding="utf-8") as f:
    for i, line in enumerate(lines, 1):
        f.write(f"{i}\n{line}\n\n")
```

---

## ğŸ“ æˆæ¬Š

æœ¬å°ˆæ¡ˆåŸºæ–¼ Meta çš„ Omnilingual ASRï¼Œéµå¾ª [Apache 2.0 æˆæ¬Š](./LICENSE)ã€‚

å¢å¼·åŠŸèƒ½ï¼ˆä¸²æµè½‰è­¯ã€è‡ªå‹•åˆ‡å‰²ï¼‰ç”±ç¤¾ç¾¤è²¢ç»ï¼ŒåŒæ¨£æ¡ç”¨ Apache 2.0 æˆæ¬Šã€‚

---

## ğŸ™ è‡´è¬

- **Meta AI** - åŸå§‹ Omnilingual ASR æ¨¡å‹
- **Fairseq2** - æ¨¡å‹æ¡†æ¶
- **ç¤¾ç¾¤è²¢ç»è€…** - ä¸²æµèˆ‡åˆ‡å‰²åŠŸèƒ½

---

## ğŸ“® æ”¯æ´

- **å•é¡Œå›å ±**ï¼š[GitHub Issues](https://github.com/omnilingual/omnilingual-asr/issues)
- **åŠŸèƒ½å»ºè­°**ï¼š[GitHub Discussions](https://github.com/omnilingual/omnilingual-asr/discussions)
- **æ–‡æª”**ï¼š[docs/](./README.md)

---

## ğŸ—ºï¸ è·¯ç·šåœ–

- [x] ä¸²æµè½‰è­¯ï¼ˆCTC + LLMï¼‰
- [x] è‡ªå‹•éŸ³è¨Šåˆ‡å‰²
- [x] ç¹é«”ä¸­æ–‡æ–‡æª”

---

**äº«å—ä½¿ç”¨ Omnilingual ASR Enhancedï¼** ğŸ‰
